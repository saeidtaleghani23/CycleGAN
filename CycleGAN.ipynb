{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 17:44:08.146775: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-08 17:44:08.188193: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-08 17:44:08.913747: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, LeakyReLU, Activation, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from instancenormalization import InstanceNormalization\n",
    "from tensorflow.keras.layers import Input, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from utils import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code has been downloaded from \n",
    "# https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/layers/normalization/instancenormalization.py\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "class InstanceNormalization(Layer):\n",
    "    \"\"\"Instance normalization layer.\n",
    "\n",
    "    Normalize the activations of the previous layer at each step,\n",
    "    i.e. applies a transformation that maintains the mean activation\n",
    "    close to 0 and the activation standard deviation close to 1.\n",
    "\n",
    "    # Arguments\n",
    "        axis: Integer, the axis that should be normalized\n",
    "            (typically the features axis).\n",
    "            For instance, after a `Conv2D` layer with\n",
    "            `data_format=\"channels_first\"`,\n",
    "            set `axis=1` in `InstanceNormalization`.\n",
    "            Setting `axis=None` will normalize all values in each\n",
    "            instance of the batch.\n",
    "            Axis 0 is the batch dimension. `axis` cannot be set to 0 to avoid errors.\n",
    "        epsilon: Small float added to variance to avoid dividing by zero.\n",
    "        center: If True, add offset of `beta` to normalized tensor.\n",
    "            If False, `beta` is ignored.\n",
    "        scale: If True, multiply by `gamma`.\n",
    "            If False, `gamma` is not used.\n",
    "            When the next layer is linear (also e.g. `nn.relu`),\n",
    "            this can be disabled since the scaling\n",
    "            will be done by the next layer.\n",
    "        beta_initializer: Initializer for the beta weight.\n",
    "        gamma_initializer: Initializer for the gamma weight.\n",
    "        beta_regularizer: Optional regularizer for the beta weight.\n",
    "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
    "        beta_constraint: Optional constraint for the beta weight.\n",
    "        gamma_constraint: Optional constraint for the gamma weight.\n",
    "\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a Sequential model.\n",
    "\n",
    "    # Output shape\n",
    "        Same shape as input.\n",
    "\n",
    "    # References\n",
    "        - [Layer Normalization](https://arxiv.org/abs/1607.06450)\n",
    "        - [Instance Normalization: The Missing Ingredient for Fast Stylization](\n",
    "        https://arxiv.org/abs/1607.08022)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 axis=None,\n",
    "                 epsilon=1e-3,\n",
    "                 center=True,\n",
    "                 scale=True,\n",
    "                 beta_initializer='zeros',\n",
    "                 gamma_initializer='ones',\n",
    "                 beta_regularizer=None,\n",
    "                 gamma_regularizer=None,\n",
    "                 beta_constraint=None,\n",
    "                 gamma_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(InstanceNormalization, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.axis = axis\n",
    "        self.epsilon = epsilon\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "        self.beta_initializer = initializers.get(beta_initializer)\n",
    "        self.gamma_initializer = initializers.get(gamma_initializer)\n",
    "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "        self.beta_constraint = constraints.get(beta_constraint)\n",
    "        self.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        ndim = len(input_shape)\n",
    "        if self.axis == 0:\n",
    "            raise ValueError('Axis cannot be zero')\n",
    "\n",
    "        if (self.axis is not None) and (ndim == 2):\n",
    "            raise ValueError('Cannot specify axis for rank 1 tensor')\n",
    "\n",
    "        self.input_spec = InputSpec(ndim=ndim)\n",
    "\n",
    "        if self.axis is None:\n",
    "            shape = (1,)\n",
    "        else:\n",
    "            shape = (input_shape[self.axis],)\n",
    "\n",
    "        if self.scale:\n",
    "            self.gamma = self.add_weight(shape=shape,\n",
    "                                         name='gamma',\n",
    "                                         initializer=self.gamma_initializer,\n",
    "                                         regularizer=self.gamma_regularizer,\n",
    "                                         constraint=self.gamma_constraint)\n",
    "        else:\n",
    "            self.gamma = None\n",
    "        if self.center:\n",
    "            self.beta = self.add_weight(shape=shape,\n",
    "                                        name='beta',\n",
    "                                        initializer=self.beta_initializer,\n",
    "                                        regularizer=self.beta_regularizer,\n",
    "                                        constraint=self.beta_constraint)\n",
    "        else:\n",
    "            self.beta = None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        reduction_axes = list(range(0, len(input_shape)))\n",
    "\n",
    "        if self.axis is not None:\n",
    "            del reduction_axes[self.axis]\n",
    "\n",
    "        del reduction_axes[0]\n",
    "\n",
    "        mean = K.mean(inputs, reduction_axes, keepdims=True)\n",
    "        stddev = K.std(inputs, reduction_axes, keepdims=True) + self.epsilon\n",
    "        normed = (inputs - mean) / stddev\n",
    "\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        if self.axis is not None:\n",
    "            broadcast_shape[self.axis] = input_shape[self.axis]\n",
    "\n",
    "        if self.scale:\n",
    "            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "            normed = normed * broadcast_gamma\n",
    "        if self.center:\n",
    "            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "            normed = normed + broadcast_beta\n",
    "        return normed\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'axis': self.axis,\n",
    "            'epsilon': self.epsilon,\n",
    "            'center': self.center,\n",
    "            'scale': self.scale,\n",
    "            'beta_initializer': initializers.serialize(self.beta_initializer),\n",
    "            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n",
    "            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n",
    "            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n",
    "            'beta_constraint': constraints.serialize(self.beta_constraint),\n",
    "            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n",
    "        }\n",
    "        base_config = super(InstanceNormalization, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded and extracted to: /home/saeid/Desktop/CycleGAN2/datasets/apple2orange.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "dataset_name = 'apple2orange'  # Other options: 'summer2winter_yosemite', 'horse2zebra', etc.\n",
    "DOWNLOAD_URL = f'http://efrosgans.eecs.berkeley.edu/cyclegan/datasets/{dataset_name}.zip'\n",
    "\n",
    "# Specify your existing download directory\n",
    "desired_directory = os.path.abspath('./datasets')  # Convert to absolute path\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(desired_directory, exist_ok=True)\n",
    "\n",
    "zip_file_path = os.path.join(desired_directory, f'{dataset_name}.zip')  # Path for the zip file\n",
    "\n",
    "# Download the dataset directly to your specified directory\n",
    "dataset_path = tf.keras.utils.get_file(\n",
    "    fname=zip_file_path,  # Save it directly in the desired directory\n",
    "    origin=DOWNLOAD_URL,\n",
    "    cache_dir=None,  # Do not use cache_dir to prevent nested folders\n",
    "    extract=False\n",
    ")\n",
    "\n",
    "# Manually unzip the dataset\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(desired_directory)\n",
    "print(f'Dataset downloaded and extracted to: {dataset_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# required function in defining Generator and Discriminator models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down sample fucntion\n",
    "def downsampling(in_layer: tf.Tensor, num_filters: int, kernel_size: int = 4, strides: int = 2) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Downsamples an input tensor using a Conv2D layer, followed by LeakyReLU activation and \n",
    "    InstanceNormalization.\n",
    "\n",
    "    Args:\n",
    "        in_layer (tf.Tensor): Input tensor to be downsampled.\n",
    "        num_filters (int): Number of filters for the Conv2D layer.\n",
    "        kernel_size (int, optional): Size of the convolutional kernel. Defaults to 4.\n",
    "        strides (int, optional): Stride size for the convolution operation. Defaults to 2.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: The downsampled output tensor after applying convolution, activation, and normalization.\n",
    "    \"\"\"\n",
    "    downsampled = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(in_layer)\n",
    "    downsampled = LeakyReLU(alpha=0.2)(downsampled)\n",
    "    downsampled = InstanceNormalization()(downsampled)\n",
    "    return downsampled\n",
    "\n",
    "# Up sample function\n",
    "def upsampling(in_layer: tf.Tensor, skip_layer: tf.Tensor, num_filters: int, kernel_size: int = 4, strides: int = 1, dropout_rate: float = 0) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Upsamples an input tensor using UpSampling2D and Conv2D layers, with optional dropout and \n",
    "    InstanceNormalization, followed by concatenation with a skip connection.\n",
    "\n",
    "    Args:\n",
    "        in_layer (tf.Tensor): Input tensor to be upsampled.\n",
    "        skip_layer (tf.Tensor): Tensor to concatenate as a skip connection with the upsampled tensor.\n",
    "        num_filters (int): Number of filters for the Conv2D layer.\n",
    "        kernel_size (int, optional): Size of the convolutional kernel. Defaults to 4.\n",
    "        strides (int, optional): Stride size for the convolution operation. Defaults to 1.\n",
    "        dropout_rate (float, optional): Dropout rate (0 means no dropout). Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: The upsampled output tensor after applying convolution, normalization, and concatenation.\n",
    "    \"\"\"\n",
    "    upsampled = UpSampling2D(size=2)(in_layer)\n",
    "    upsampled = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same', activation='relu')(upsampled)\n",
    "    if dropout_rate:\n",
    "        upsampled = Dropout(dropout_rate)(upsampled)\n",
    "    upsampled = InstanceNormalization()(upsampled)\n",
    "    upsampled = Concatenate()([upsampled, skip_layer])\n",
    "    return upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define U-Net shape generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(img_shape: tuple, in_channels: int = 3, num_filters: int = 32) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Builds a U-Net style generator model with downsampling and upsampling layers, often used for \n",
    "    image generation tasks.\n",
    "\n",
    "    Args:\n",
    "        img_shape (tuple): Shape of the input image (height, width, channels).\n",
    "        in_channels (int, optional): Number of channels in the output image. Defaults to 3.\n",
    "        num_filters (int, optional): Base number of filters for the downsampling layers. Defaults to 32.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The generator model built with U-Net architecture.\n",
    "    \"\"\"\n",
    "    # image shape\n",
    "    input_layer = Input(shape=img_shape)\n",
    "    \n",
    "    # downsampling in U-Net model\n",
    "    down_sample_1 = downsampling(in_layer=input_layer, num_filters=num_filters)\n",
    "    down_sample_2 = downsampling(in_layer=down_sample_1, num_filters=2 * num_filters)\n",
    "    down_sample_3 = downsampling(in_layer=down_sample_2, num_filters=4 * num_filters)\n",
    "    bottleneck = downsampling(in_layer=down_sample_3, num_filters=8 * num_filters)\n",
    "    \n",
    "    # upsampling in U-Net model\n",
    "    upsample_1 = upsampling(in_layer=bottleneck, skip_layer=down_sample_3, num_filters=4 * num_filters)\n",
    "    upsample_2 = upsampling(in_layer=upsample_1, skip_layer=down_sample_2, num_filters=2 * num_filters)\n",
    "    upsample_3 = upsampling(in_layer=upsample_2, skip_layer=down_sample_1, num_filters=num_filters)\n",
    "    upsample_4 = UpSampling2D(size=2)(upsample_3)\n",
    "    \n",
    "    # output layer\n",
    "    output_img = Conv2D(in_channels, kernel_size=4, strides=1, padding='same', activation='tanh')(upsample_4)\n",
    "    \n",
    "    # return the generative model\n",
    "    return Model(input_layer, output_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_block(in_layer: tf.Tensor, num_filters: int, kernel_size: int = 4, instance_normalization: bool = True) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Builds a convolutional block with Conv2D, LeakyReLU activation, and optional InstanceNormalization, \n",
    "    commonly used in discriminator networks.\n",
    "\n",
    "    Args:\n",
    "        in_layer (tf.Tensor): Input tensor for the block.\n",
    "        num_filters (int): Number of filters for the Conv2D layer.\n",
    "        kernel_size (int, optional): Size of the convolutional kernel. Defaults to 4.\n",
    "        instance_normalization (bool, optional): Whether to apply InstanceNormalization. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: The output tensor after applying convolution, activation, and optional normalization.\n",
    "    \"\"\"\n",
    "    disc_layer = Conv2D(num_filters, kernel_size=kernel_size, strides=2, padding='same')(in_layer)\n",
    "    disc_layer = LeakyReLU(alpha=0.2)(disc_layer)\n",
    "    if instance_normalization:\n",
    "        disc_layer = InstanceNormalization()(disc_layer)\n",
    "    return disc_layer\n",
    "\n",
    "def build_discriminator(img_shape: tuple, num_filters: int = 64) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Builds a discriminator model using multiple convolutional blocks and outputs a single-channel \n",
    "    feature map. The model uses a sequence of downsampling layers with increasing filter sizes.\n",
    "\n",
    "    Args:\n",
    "        img_shape (tuple): Shape of the input image (height, width, channels).\n",
    "        num_filters (int, optional): Base number of filters for the first convolutional block. Defaults to 64.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The discriminator model built for distinguishing between real and generated images.\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=img_shape)\n",
    "    \n",
    "    # First block, without instance normalization\n",
    "    disc_block_1 = disc_block(input_layer, num_filters=num_filters, instance_normalization=False)\n",
    "    \n",
    "    # Subsequent blocks with increasing filters\n",
    "    disc_block_2 = disc_block(disc_block_1, num_filters * 2)\n",
    "    disc_block_3 = disc_block(disc_block_2, num_filters * 4)\n",
    "    disc_block_4 = disc_block(disc_block_3, num_filters * 8)\n",
    "    \n",
    "    # Final output layer\n",
    "    disc_output = Conv2D(1, kernel_size=4, strides=1, padding='same')(disc_block_4)\n",
    "    \n",
    "    # Return the discriminator model\n",
    "    return Model(input_layer, disc_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_filter = 32\n",
    "discriminator_filters = 64\n",
    "# image shape\n",
    "image_height = 128\n",
    "image_width = 128\n",
    "# input shape\n",
    "channels = 3\n",
    "input_shape = (image_height, image_width, channels)\n",
    "# loss weights\n",
    "lambda_cycle = 10.0\n",
    "lambda_identity = 0.1 * lambda_cycle\n",
    "# optimizer\n",
    "optimizer = Adam (learning_rate= 0.0002, beta_1= 0.5)\n",
    "\n",
    "patch = int (image_height / 2**4)\n",
    "patch_gan_shape = (patch, patch, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saeid/anaconda3/lib/python3.11/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# discriminator models \n",
    "disc_A = build_discriminator(img_shape = input_shape, num_filters = discriminator_filters)\n",
    "disc_A.compile(loss = 'mse',\n",
    "optimizer = optimizer,\n",
    "metrics = ['accuracy'])\n",
    "\n",
    "disc_B = build_discriminator(img_shape = input_shape, num_filters = discriminator_filters)\n",
    "disc_B.compile(loss = 'mse',\n",
    "optimizer = optimizer,\n",
    "metrics = ['accuracy'])\n",
    "\n",
    "# generators model \n",
    "gen_AtoB = build_generator(img_shape = input_shape, in_channels = channels, num_filters = generator_filter)\n",
    "gen_BtoA = build_generator(img_shape = input_shape, in_channels = channels, num_filters = generator_filter)\n",
    "\n",
    "#CycleGAN model\n",
    "real_image_A = Input(shape=input_shape)\n",
    "real_image_B = Input(shape=input_shape)\n",
    "# generate fake samples from both generators\n",
    "fake_image_B = gen_AtoB(real_image_A)\n",
    "fake_image_A = gen_BtoA(real_image_B)\n",
    "\n",
    "# *****Reconstruction Loss*****\n",
    "# reconstruct original samples from both generators using fake images \n",
    "reconstruct_A = gen_BtoA(fake_image_B) # it must be similar to real images from domain A\n",
    "reconstruct_B = gen_AtoB(fake_image_A) # it must be similar to real images from domain B\n",
    "\n",
    "# *****Identity Loss*****\n",
    "# generate identity samples\n",
    "identity_A = gen_BtoA(real_image_A) # it must be equal to real image from domain A\n",
    "identity_B = gen_AtoB(real_image_B) # it must be equal to real image from domain B\n",
    "# disable discriminator training\n",
    "disc_A.trainable = False\n",
    "disc_B.trainable = False\n",
    "\n",
    "# *****Adversarial Loss*****\n",
    "# use discriminator to classify real vs fake \n",
    "output_A = disc_A(fake_image_A)\n",
    "output_B = disc_B(fake_image_B)\n",
    "# Combined model trains generators to fool discriminators to fool discriminators\n",
    "cycle_gan = Model(inputs= [real_image_A, real_image_B],\n",
    "            outputs = [output_A, output_B, reconstruct_A, reconstruct_B, identity_A, identity_B])\n",
    "\n",
    "cycle_gan.compile (loss = ['mse', 'mse', 'mae', 'mae', 'mae', 'mae'], # mse  is used for Adversarial losses while mae is used for identity and reconstruction losses\n",
    "             loss_weights = [1, 1, lambda_cycle, lambda_cycle, lambda_identity, lambda_identity], # how losses are combined to get final loss value\n",
    "             optimizer= optimizer # which optimizer is used\n",
    "             ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CycleGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainig(gen_AtoB,\n",
    "                gen_BtoA, \n",
    "                disc_A, \n",
    "                disc_B, \n",
    "                cyclegan, \n",
    "                patch_gan_shape, \n",
    "                epochs,\n",
    "                path= '/datasets/{}'.format(dataset_name),\n",
    "                batch_size = 1, \n",
    "                sample_interval = 50):\n",
    "    # Adversarial loss ground truths\n",
    "    print(f'path to dataset: {path}')\n",
    "    real_labels = np.ones((batch_size,) + patch_gan_shape)\n",
    "    fake_labels = np.zeros((batch_size,) + patch_gan_shape)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch={epoch}')\n",
    "        for idx, (imgs_A, imgs_B) in enumerate(batch_generator(path, batch_size, image_res=[image_height, image_width])) :\n",
    "            # generate fake smaples from both generators\n",
    "            fake_B = gen_AtoB.predict(imgs_A)\n",
    "            fake_A = gen_BtoA.predict(imgs_B)\n",
    "            \n",
    "            # Train discriminators\n",
    "            disc_A_loss_real = disc_A.train_on_batch(imgs_A, real_labels)\n",
    "            disc_A_loss_fake = disc_A.train_on_batch(fake_A, fake_labels)\n",
    "            disc_A_loss = 0.5 * np.add(disc_A_loss_real, disc_A_loss_fake)\n",
    "            \n",
    "            disc_B_loss_real = disc_B.train_on_batch(imgs_B, real_labels)\n",
    "            disc_B_loss_fake = disc_B.train_on_batch(imgs_B, fake_labels)\n",
    "            disc_B_loss = 0.5 * np.add(disc_B_loss_real, disc_B_loss_fake)\n",
    "            # total discriminator loss\n",
    "            discriminator_loss = 0.5 * np.add(disc_A_loss, disc_B_loss)\n",
    "            \n",
    "            # Train generator\n",
    "            gen_loss = cycle_gan.train_on_batch([imgs_A, imgs_B],\n",
    "                                                [\n",
    "                                                 real_labels, real_labels, \n",
    "                                                 imgs_A, imgs_B,\n",
    "                                                 imgs_A, imgs_B\n",
    "                                                 ]\n",
    "                                                )\n",
    "            # training updates every 50 iterations\n",
    "            if idx % 50 == 0:\n",
    "                print(f'[Epoch {idx}/{epoch}] '\n",
    "                        f'[Discriminator loss: {discriminator_loss[0]} Accuracy: {100 * discriminator_loss[1]:.2f}] '\n",
    "                        f'[Adversarial loss (A to B): {gen_loss[0]}] '\n",
    "                        f'[Adversarial loss (B to A): {gen_loss[1]}] '\n",
    "                        f'[Reconstruction loss (A): {gen_loss[2]}] '\n",
    "                        f'[Reconstruction loss (B): {gen_loss[3]}] '\n",
    "                        f'[Identity loss (A): {gen_loss[4]}] '\n",
    "                        f'[Identity loss (B): {gen_loss[5]}]')\n",
    "            \n",
    "            # plot and save progress every few iterations\n",
    "            if idx % sample_interval == 0:\n",
    "                plot_sample_images(gen_AtoB, \n",
    "                                   gen_BtoA,\n",
    "                                   path=path,\n",
    "                                   epoch = epoch,\n",
    "                                   batch_num= idx,\n",
    "                                   output_dir= 'outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path to dataset: /datasets/apple2orange\n",
      "Epoch=0\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=1\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=2\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=3\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=4\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=5\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=6\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=7\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=8\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=9\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=10\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=11\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=12\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=13\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=14\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=15\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=16\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=17\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=18\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=19\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=20\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=21\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=22\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=23\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=24\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=25\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=26\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=27\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=28\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=29\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=30\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=31\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=32\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=33\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=34\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=35\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=36\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=37\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=38\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=39\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=40\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=41\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=42\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=43\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=44\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=45\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=46\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=47\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=48\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=49\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=50\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=51\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=52\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=53\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=54\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=55\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=56\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=57\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=58\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=59\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=60\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=61\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=62\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=63\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=64\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=65\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=66\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=67\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=68\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=69\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=70\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=71\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=72\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=73\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=74\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=75\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=76\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=77\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=78\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=79\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=80\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=81\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=82\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=83\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=84\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=85\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=86\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=87\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=88\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=89\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=90\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=91\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=92\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=93\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=94\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=95\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=96\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=97\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=98\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=99\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=100\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=101\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=102\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=103\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=104\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=105\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=106\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=107\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=108\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=109\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=110\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=111\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=112\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=113\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=114\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=115\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=116\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=117\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=118\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=119\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=120\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=121\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=122\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=123\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=124\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=125\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=126\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=127\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=128\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=129\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=130\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=131\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=132\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=133\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=134\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=135\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=136\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=137\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=138\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=139\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=140\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=141\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=142\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=143\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=144\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=145\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=146\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=147\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=148\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=149\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=150\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=151\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=152\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=153\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=154\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=155\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=156\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=157\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=158\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=159\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=160\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=161\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=162\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=163\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=164\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=165\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=166\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=167\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=168\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=169\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=170\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=171\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=172\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=173\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=174\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=175\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=176\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=177\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=178\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=179\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=180\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=181\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=182\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=183\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=184\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=185\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=186\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=187\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=188\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=189\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=190\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=191\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=192\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=193\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=194\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=195\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=196\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=197\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=198\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n",
      "Epoch=199\n",
      " path to domain A dataset: []\n",
      " path to domain B dataset: []\n"
     ]
    }
   ],
   "source": [
    "trainig(gen_AtoB, \n",
    "      gen_BtoA, \n",
    "      disc_A, \n",
    "      disc_B, \n",
    "      cycle_gan, \n",
    "      patch_gan_shape, \n",
    "      epochs=200, \n",
    "      batch_size=1, \n",
    "      sample_interval=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
